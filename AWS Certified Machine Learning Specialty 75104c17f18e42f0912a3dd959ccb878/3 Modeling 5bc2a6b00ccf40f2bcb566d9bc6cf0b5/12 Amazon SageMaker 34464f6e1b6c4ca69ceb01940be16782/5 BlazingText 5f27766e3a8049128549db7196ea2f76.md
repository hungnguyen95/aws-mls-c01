# 5. BlazingText

## BlazingText: What’s it for?

- Text classification
    - Predict labels for a sentence
    - Useful in web searches, information retrieval
    - Supervised
- Word2vec
    - Creates a vector representation of words
    - Semantically similar words are represented by vectors close to each other
    - This is called a word embedding
    - It is useful for NLP, but is not an NLP algorithm in itself!
    - Used in machine translation, sentiment analysis
    - Remember it only works on individual words, not sentences or documents

---

## BlazingText: What training input does it expect?

- For supervised mode (text classification):
    - One sentence per line
    - First “word” in the sentence is the string__label__ followed by the label
- Also, “augmented manifest text format”
- Word2vec just wants a text file with one training sentence per line.

```json
__label__4 linux ready for prime time , intel says , despite all the linux hype , the open-source
movement has yet to make a huge splash in the desktop market . that may be about to change ,
thanks to chipmaking giant intel corp .

__label__2 bowled by the slower one again , kolkata , november 14 the past caught up with
sourav ganguly as the indian skippers return to international cricket was short lived .

{"source":"linux ready for prime time , intel says , despite all the linux hype", "label":1}

{"source":"bowled by the slower one again , kolkata , november 14 the past caught up with
sourav ganguly", "label":2}
```

---

## BlazingText: How is it used?

- Word2vec has multiple modes
    - Cbow (Continuous Bag of Words)
    - Skip-gram
    - Batch skip-gram
        - Distributed computation over many CPU nodes

---

## BlazingText: Important Hyperparameters

- Word2vec:
    - Mode (batch_skipgram, skipgram, cbow)
    - Learning_rate
    - Window_size
    - Vector_dim
    - Negative_samples
- Text classification:
    - Epochs
    - Learning_rate
    - Word_ngrams
    - Vector_dim

---

## BlazingText: Instance Types

- For cbow and skipgram, recommend a single ml.p3.2xlarge
    - Any single CPU or single GPU instance will work
- For batch_skipgram, can use single or multiple CPU instances
- For text classification, C5 recommended if less than 2GB training data. For larger data sets, use a single GPU instance (ml.p2.xlarge or ml.p3.2xlarge)