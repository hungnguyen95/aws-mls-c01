# 13. KNN

## KNN: What’s it for?

- K-Nearest-Neighbors
- Simple classification or regression algorithm
- Classification
    - Find the K closest points to a sample point and return the most frequent label
- Regression
    - Find the K closest points to a sample point and return the average value

![13%20KNN%20cc7f7e6f0a0647c082fa8edd5d133528/Untitled.png](13%20KNN%20cc7f7e6f0a0647c082fa8edd5d133528/Untitled.png)

---

## KNN: What training input does it expect?

- Train channel contains your data
- Test channel emits accuracy or MSE
- recordIO-protobuf or CSV training
    - First column is label
- File or pipe mode on either

---

## KNN: How is it used?

- Data is first sampled
- SageMaker includes a dimensionality reduction stage
- Avoid sparse data (“curse of dimensionality”)
- At cost of noise / accuracy
- “sign” or “fjlt” methods
- Build an index for looking up neighbors
- Serialize the model
- Query the model for a given K

---

## KNN: Important Hyperparameters

- K!
- Sample_size

---

## KNN: Instance Types

- Training on CPU or GPU
    - Ml.m5.2xlarge
    - Ml.p2.xlarge
- Inference
    - CPU for lower latency
    - GPU for higher throughput on large batches