# 12. LDA

## LDA: Whatâ€™s it for?

- Latent Dirichlet Allocation
- Another topic modeling algorithm
    - Not deep learning
- Unsupervised
    - The topics themselves are unlabeled;they are just groupings of documents with a shared subset of words
- Can be used for things other than words
    - Cluster customers based on purchases
    - Harmonic analysis in music

---

## LDA: What training input does it expect?

- Train channel, optional test channel
- recordIO-protobuf or CSV
- Each document has counts for every word in vocabulary (in CSV format)
- Pipe mode only supported with recordIO

---

## LDA: How is it used?

- Unsupervised; generates however many topics you specify
- Optional test channel can be used for scoring results
    - Per-word log likelihood
- Functionally similar to NTM, but CPU-based
    - Therefore maybe cheaper / more efficient

---

## LDA: Important Hyperparameters

- Num_topics
- Alpha0
- Initial guess for concentration parameter
- Smaller values generate sparse topicmixtures
- Larger values (>1.0) produce uniform mixtures

---

## LDA: Instance Types

- Single-instance CPU training