# 6. Object2Vec

## Object2Vec: What’s it for?

- Remember word2vec from Blazing Text? It’s like that, but arbitrary objects
- It creates low-dimensional dense embeddings of high-dimensional objects
- It is basically word2vec, generalized to handle things other than words.
- Compute nearest neighbors of objects
- Visualize clusters
- Genre prediction
- Recommendations (similar items or users)
- Unsupervised

---

## Object2Vec: What training input does it expect?

- Data must be tokenized into integers
- Training data consists of pairs of tokens and/or sequences of tokens
    - Sentence – sentence
    - Labels-sequence (genre to description?)
    - Customer-customer
    - Product-product
    - User-item

```json
{"label": 0, "in0": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821, 4], "in1": [16, 21, 13, 45, 14, 9, 80, 59, 164, 4]}
{"label": 1, "in0": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4], "in1": [22, 32, 13, 25, 1016, 573, 3252, 4]}
{"label": 1, "in0": [774, 14, 21, 206], "in1": [21, 366, 125]}
```

---

## Object2Vec: How is it used?

- Process data into JSON Lines and shuffle it
- Train with two input channels, two encoders, and a comparator
- Encoder choices:
    - Average-pooled embeddings
    - CNN’s
    - Bidirectional LSTM
- Comparator is followed by a feed-forward neural network

![6%20Object2Vec%20d8081218ad9743b88c2537ae3e4873b2/Untitled.png](6%20Object2Vec%20d8081218ad9743b88c2537ae3e4873b2/Untitled.png)

---

## Object2Vec: Important Hyperparameters

- The usual deep learning ones…
    - Dropout, early stopping, epochs, learning rate, batch size, layers, activation function, optimizer, weight decay
- Enc1_network, enc2_network
    - Choose hcnn, bilstm, pooled_embedding

---

## Object2Vec: Instance Types

- Can only train on a single machine (CPU or GPU, multi-GPU OK)
    - Ml.m5.2xlarge
    - Ml.p2.xlarge
    - If needed, go up to ml.m5.4xlarge or ml.m5.12xlarge
- Inference: use ml.p2.2xlarge
    - Use INFERENCE_PREFERRED_MODE environment variable to optimize for encoder embeddings rather than classification or regression.